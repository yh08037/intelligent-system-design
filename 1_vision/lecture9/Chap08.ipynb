{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8장 딥러닝\n",
    "딥러닝은 층을 깊게 한 심층 신경망입니다. 심층 신경망은 지금까지 설명한 신경망을 바탕으로 뒷단에 층을 추가하기만 하면 만들 수 있지만, 커다란 문제가 몇 개 있습니다. 이번 장에서는 딥러닝의 특징과 과제, 그리고 가능성을 살펴봅니다. 또 오늘날의 첨단 딥러닝에 대한 설명도 준비했습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Copyrights\n",
    "1. https://github.com/WegraLee/deep-learning-from-scratch\n",
    "\n",
    "### Customized by Gil-Jin Jang, May 6, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파일 설명\n",
    "| 파일명 | 파일 용도 | 관련 절 | 페이지 |\n",
    "|:--   |:--      |:--    |:--      |\n",
    "| awesome_net.py | 빈 파일입니다. 여기에 여러분만의 멋진 신경망을 구현해보세요! |  |  |\n",
    "| deep_convnet.py | [그림 8-1]의 깊은 신경망을 구현한 소스입니다. | 8.1.1 더 깊은 신경망으로 | 262 |\n",
    "| train_deepnet.py | deep_convnet.py의 신경망을 학습시킵니다. 몇 시간은 걸리기 때문에 다른 코드에서는 미리 학습된 가중치인 deep_convnet_params.pkl을 읽어서 사용합니다. | 8.1.1 더 깊은 신경망으로 | 262 |\n",
    "| deep_convnet_params.pkl | deep_convnet.py용 학습된 가중치입니다. |  |  |\n",
    "| misclassified_mnist.py | 이번 장에서 구현한 신경망이 인식에 실패한 손글씨 이미지들을 화면에 보여줍니다. | 8.1.1 더 깊은 신경망으로 | 263 |\n",
    "| half_float_network.py | 수치 정밀도를 반정밀도(16비트)로 낮춰 계산하여 배정밀도(64비트)일 때와 정확도를 비교해본다. | 8.3.4 연산 정밀도와 비트 줄이기 | 278 |\n",
    "\n",
    "\n",
    "## 목차\n",
    "```\n",
    "8.1 더 깊게 \n",
    "__8.1.1 더 깊은 네트워크로 \n",
    "__8.1.2 정확도를 더 높이려면 \n",
    "__8.1.3 깊게 하는 이유 \n",
    "8.2 딥러닝의 초기 역사 \n",
    "__8.2.1 이미지넷 \n",
    "__8.2.2 VGG \n",
    "__8.2.3 GoogLeNet \n",
    "__8.2.4 ResNet \n",
    "8.3 더 빠르게(딥러닝 고속화) \n",
    "__8.3.1 풀어야 할 숙제 \n",
    "__8.3.2 GPU를 활용한 고속화 \n",
    "__8.3.3 분산 학습 \n",
    "__8.3.4 연산 정밀도와 비트 줄이기 \n",
    "8.4 딥러닝의 활용 \n",
    "__8.4.1 사물 검출 \n",
    "__8.4.2 분할 \n",
    "__8.4.3 사진 캡션 생성 \n",
    "8.5 딥러닝의 미래 \n",
    "__8.5.1 이미지 스타일(화풍) 변환 \n",
    "__8.5.2 이미지 생성 \n",
    "__8.5.3 자율 주행 \n",
    "__8.5.4 Deep Q-Network(강화학습) \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 더 깊게 \n",
    "### 8.1.1 더 깊은 네트워크로 \n",
    "\n",
    "<img src=\"images/fig 8-1.png\">손글씨 심층 CNN</img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "# deep_conv_net.py\n",
    "# [그림 8-1]의 깊은 신경망을 구현한 소스입니다.\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from common.layers import *\n",
    "\n",
    "\n",
    "class DeepConvNet:\n",
    "    \"\"\"정확도 99% 이상의 고정밀 합성곱 신경망\n",
    "\n",
    "    네트워크 구성은 아래와 같음\n",
    "        conv - relu - conv- relu - pool -\n",
    "        conv - relu - conv- relu - pool -\n",
    "        conv - relu - conv- relu - pool -\n",
    "        affine - relu - dropout - affine - dropout - softmax\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=(1, 28, 28),\n",
    "                 conv_param_1 = {'filter_num':16, 'filter_size':3, 'pad':1, 'stride':1},\n",
    "                 conv_param_2 = {'filter_num':16, 'filter_size':3, 'pad':1, 'stride':1},\n",
    "                 conv_param_3 = {'filter_num':32, 'filter_size':3, 'pad':1, 'stride':1},\n",
    "                 conv_param_4 = {'filter_num':32, 'filter_size':3, 'pad':2, 'stride':1},\n",
    "                 conv_param_5 = {'filter_num':64, 'filter_size':3, 'pad':1, 'stride':1},\n",
    "                 conv_param_6 = {'filter_num':64, 'filter_size':3, 'pad':1, 'stride':1},\n",
    "                 hidden_size=50, output_size=10):\n",
    "        # 가중치 초기화===========\n",
    "        # 각 층의 뉴런 하나당 앞 층의 몇 개 뉴런과 연결되는가（TODO: 자동 계산되게 바꿀 것）\n",
    "        pre_node_nums = np.array([1*3*3, 16*3*3, 16*3*3, 32*3*3, 32*3*3, 64*3*3, 64*4*4, hidden_size])\n",
    "        wight_init_scales = np.sqrt(2.0 / pre_node_nums)  # ReLU를 사용할 때의 권장 초깃값\n",
    "        \n",
    "        self.params = {}\n",
    "        pre_channel_num = input_dim[0]\n",
    "        for idx, conv_param in enumerate([conv_param_1, conv_param_2, conv_param_3, conv_param_4, conv_param_5, conv_param_6]):\n",
    "            self.params['W' + str(idx+1)] = wight_init_scales[idx] * np.random.randn(conv_param['filter_num'], pre_channel_num, conv_param['filter_size'], conv_param['filter_size'])\n",
    "            self.params['b' + str(idx+1)] = np.zeros(conv_param['filter_num'])\n",
    "            pre_channel_num = conv_param['filter_num']\n",
    "        self.params['W7'] = wight_init_scales[6] * np.random.randn(64*4*4, hidden_size)\n",
    "        self.params['b7'] = np.zeros(hidden_size)\n",
    "        self.params['W8'] = wight_init_scales[7] * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b8'] = np.zeros(output_size)\n",
    "\n",
    "        # 계층 생성===========\n",
    "        self.layers = []\n",
    "        self.layers.append(Convolution(self.params['W1'], self.params['b1'], \n",
    "                           conv_param_1['stride'], conv_param_1['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Convolution(self.params['W2'], self.params['b2'], \n",
    "                           conv_param_2['stride'], conv_param_2['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Pooling(pool_h=2, pool_w=2, stride=2))\n",
    "        self.layers.append(Convolution(self.params['W3'], self.params['b3'], \n",
    "                           conv_param_3['stride'], conv_param_3['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Convolution(self.params['W4'], self.params['b4'],\n",
    "                           conv_param_4['stride'], conv_param_4['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Pooling(pool_h=2, pool_w=2, stride=2))\n",
    "        self.layers.append(Convolution(self.params['W5'], self.params['b5'],\n",
    "                           conv_param_5['stride'], conv_param_5['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Convolution(self.params['W6'], self.params['b6'],\n",
    "                           conv_param_6['stride'], conv_param_6['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Pooling(pool_h=2, pool_w=2, stride=2))\n",
    "        self.layers.append(Affine(self.params['W7'], self.params['b7']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Dropout(0.5))\n",
    "        self.layers.append(Affine(self.params['W8'], self.params['b8']))\n",
    "        self.layers.append(Dropout(0.5))\n",
    "        \n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "\n",
    "    def predict(self, x, train_flg=False):\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, Dropout):\n",
    "                x = layer.forward(x, train_flg)\n",
    "            else:\n",
    "                x = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x, train_flg=True)\n",
    "        return self.last_layer.forward(y, t)\n",
    "\n",
    "    def accuracy(self, x, t, batch_size=100):\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "\n",
    "        acc = 0.0\n",
    "\n",
    "        for i in range(int(x.shape[0] / batch_size)):\n",
    "            tx = x[i*batch_size:(i+1)*batch_size]\n",
    "            tt = t[i*batch_size:(i+1)*batch_size]\n",
    "            y = self.predict(tx, train_flg=False)\n",
    "            y = np.argmax(y, axis=1)\n",
    "            acc += np.sum(y == tt)\n",
    "\n",
    "        return acc / x.shape[0]\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "\n",
    "        tmp_layers = self.layers.copy()\n",
    "        tmp_layers.reverse()\n",
    "        for layer in tmp_layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 결과 저장\n",
    "        grads = {}\n",
    "        for i, layer_idx in enumerate((0, 2, 5, 7, 10, 12, 15, 18)):\n",
    "            grads['W' + str(i+1)] = self.layers[layer_idx].dW\n",
    "            grads['b' + str(i+1)] = self.layers[layer_idx].db\n",
    "\n",
    "        return grads\n",
    "\n",
    "    def save_params(self, file_name=\"params.pkl\"):\n",
    "        params = {}\n",
    "        for key, val in self.params.items():\n",
    "            params[key] = val\n",
    "        with open(file_name, 'wb') as f:\n",
    "            pickle.dump(params, f)\n",
    "\n",
    "    def load_params(self, file_name=\"params.pkl\"):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            params = pickle.load(f)\n",
    "        for key, val in params.items():\n",
    "            self.params[key] = val\n",
    "\n",
    "        for i, layer_idx in enumerate((0, 2, 5, 7, 10, 12, 15, 18)):\n",
    "            self.layers[layer_idx].W = self.params['W' + str(i+1)]\n",
    "            self.layers[layer_idx].b = self.params['b' + str(i+1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "# train_deepnet.py\n",
    "# deep_convnet_params.pkl \n",
    "# deep_convnet.py의 신경망을 학습시킵니다. 몇 시간은 걸리기 때문에 다른 코드에서는 미리 학습된 가중치인 deep_convnet_params.pkl을 읽어서 사용합니다. | 8.1.1 더 깊은 신경망으로 | 262 |\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from deep_convnet import DeepConvNet\n",
    "from common.trainer import Trainer\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "network = DeepConvNet()  \n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=20, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr':0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()\n",
    "\n",
    "# 매개변수 보관\n",
    "network.save_params(\"deep_convnet_params.pkl\")\n",
    "print(\"Saved Network Parameters!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# misclassified_mnist.py \n",
    "# 이번 장에서 구현한 신경망이 인식에 실패한 손글씨 이미지들을 화면에 보여줍니다.\n",
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from deep_convnet import DeepConvNet\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "network = DeepConvNet()\n",
    "network.load_params(\"deep_convnet_params.pkl\")\n",
    "\n",
    "print(\"calculating test accuracy ... \")\n",
    "#sampled = 1000\n",
    "#x_test = x_test[:sampled]\n",
    "#t_test = t_test[:sampled]\n",
    "\n",
    "classified_ids = []\n",
    "\n",
    "acc = 0.0\n",
    "batch_size = 100\n",
    "\n",
    "for i in range(int(x_test.shape[0] / batch_size)):\n",
    "    tx = x_test[i*batch_size:(i+1)*batch_size]\n",
    "    tt = t_test[i*batch_size:(i+1)*batch_size]\n",
    "    y = network.predict(tx, train_flg=False)\n",
    "    y = np.argmax(y, axis=1)\n",
    "    classified_ids.append(y)\n",
    "    acc += np.sum(y == tt)\n",
    "    \n",
    "acc = acc / x_test.shape[0]\n",
    "print(\"test accuracy:\" + str(acc))\n",
    "\n",
    "classified_ids = np.array(classified_ids)\n",
    "classified_ids = classified_ids.flatten()\n",
    " \n",
    "max_view = 20\n",
    "current_view = 1\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.2, wspace=0.2)\n",
    "\n",
    "mis_pairs = {}\n",
    "for i, val in enumerate(classified_ids == t_test):\n",
    "    if not val:\n",
    "        ax = fig.add_subplot(4, 5, current_view, xticks=[], yticks=[])\n",
    "        ax.imshow(x_test[i].reshape(28, 28), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "        mis_pairs[current_view] = (t_test[i], classified_ids[i])\n",
    "            \n",
    "        current_view += 1\n",
    "        if current_view > max_view:\n",
    "            break\n",
    "\n",
    "print(\"======= misclassified result =======\")\n",
    "print(\"{view index: (label, inference), ...}\")\n",
    "print(mis_pairs)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/fig 8-2.png\">인식하지 못한(misclassified) 이미지들</img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1.2 정확도를 더 높이려면 \n",
    "\n",
    "<img src=\"images/fig 8-3.png\">MNIST rankings</img>\n",
    "\n",
    "<img src=\"images/fig 8-4.png\">Data augmentation</img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1.3 깊게 하는 이유 \n",
    "\n",
    "<img src=\"images/fig 8-5.png\">5x5 convolution</img>\n",
    "\n",
    "<img src=\"images/fig 8-6.png\">Multiple 3x3 convoltions</img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 딥러닝의 초기 역사 \n",
    "### 8.2.1 이미지넷 \n",
    "<img src=\"images/fig 8-7.png\">ImageNet samples</img>\n",
    "\n",
    "<img src=\"images/fig 8-8.png\">ILSVRC rankings</img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.2 VGG \n",
    "<img src=\"images/fig 8-9.png\">VGGNet</img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.3 GoogLeNet \n",
    "<img src=\"images/fig 8-10.png\">GoogLeNet</img>\n",
    "\n",
    "<img src=\"images/fig 8-11.png\">Inception module in GoogLeNet</img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.4 ResNet \n",
    "<img src=\"images/fig 8-12.png\">ResNet module</img>\n",
    "\n",
    "<img src=\"images/fig 8-13.png\">RegNet</img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3 더 빠르게(딥러닝 고속화) \n",
    "### 8.3.1 풀어야 할 숙제 \n",
    "<img src=\"images/fig 8-14.png\">AlextNet forward 처리시 각 층의 시간비율</img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3.2 GPU를 활용한 고속화 \n",
    "<img src=\"images/fig 8-15.png\">AlexNet 시간비교</img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3.3 분산 학습 \n",
    "<img src=\"images/fig 8-16.png\">완전연결 계층(Affine 계층)으로 이루어진 네트워크의 예</img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3.4 연산 정밀도와 비트 줄이기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# half_float_network.py \n",
    "# 수치 정밀도를 반정밀도(16비트)로 낮춰 계산하여 배정밀도(64비트)일 때와 정확도를 비교해본다.\n",
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from deep_convnet import DeepConvNet\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "network = DeepConvNet()\n",
    "network.load_params(\"deep_convnet_params.pkl\")\n",
    "\n",
    "sampled = 10000 # 고속화를 위한 표본추출\n",
    "x_test = x_test[:sampled]\n",
    "t_test = t_test[:sampled]\n",
    "\n",
    "print(\"caluculate accuracy (float64) ... \")\n",
    "print(network.accuracy(x_test, t_test))\n",
    "\n",
    "# float16(반정밀도)로 형변환\n",
    "x_test = x_test.astype(np.float16)\n",
    "for param in network.params.values():\n",
    "    param[...] = param.astype(np.float16)\n",
    "\n",
    "print(\"caluculate accuracy (float16) ... \")\n",
    "print(network.accuracy(x_test, t_test)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.4 딥러닝의 활용 \n",
    "### 8.4.1 사물 검출 \n",
    "<img src=\"images/fig 8-17.png\">사물 검출의 예시</img>\n",
    "\n",
    "<img src=\"images/fig 8-18.png\">R-CNN</img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4.2 분할 \n",
    "<img src=\"images/fig 8-19.png\">Segmentation</img>\n",
    "\n",
    "<img src=\"images/fig 8-20.png\">FCN</img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4.3 사진 캡션 생성 \n",
    "<img src=\"images/fig 8-21.png\">Image Captioning</img>\n",
    "\n",
    "<img src=\"images/fig 8-22.png\">NIC</img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.5 딥러닝의 미래 \n",
    "### 8.5.1 이미지 스타일(화풍) 변환 \n",
    "<img src=\"images/fig 8-23.png\">A Neural Algorithm of Artistic Style</img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5.2 이미지 생성 \n",
    "<img src=\"images/fig 8-24.png\">DCGAN</img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5.3 자율 주행 \n",
    "<img src=\"images/fig 8-25.png\">딥러닝을 활용한 이미지 분할의 예</img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5.4 Deep Q-Network(강화학습) \n",
    "<img src=\"images/fig 8-26.png\">강화학습의 기본 틀</img>\n",
    "\n",
    "<img src=\"images/fig 8-27.png\">Deep Q-Network</img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이번 장에서 배운 내용\n",
    "* 수많은 문제에서 신경망을 더 깊게 하여 성능을 개선할 수 있다.\n",
    "* 이미지 인식 기술 대회인 ILSVRC에서는 최근 딥러닝 기반 기법이 상위권을 독점하고 있으며, 그 깊이도 더 깊어지는 추세다.\n",
    "* 유명한 신경망으로는 VGG, GoogLeNet, ResNet이 있다.\n",
    "* GPU와 분산 학습, 비트 정밀도 감소 등으로 딥러닝을 고속화할 수 있다.\n",
    "* 딥러닝(신경망)은 사물 인식뿐 아니라 사물 검출과 분할에도 이용할 수 있다.\n",
    "* 딥러닝의 응용 분야로는 사진의 캡션 생성, 이미지 생성, 강화학습 등이 있다. 최근에는 자율 주행에도 딥러닝을 접목하고 있어 기대된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 더 깊게 \n",
    "### 8.1.1 더 깊은 네트워크로 \n",
    "\n",
    "<img src=\"images/fig 8-1.png\">손글씨 심층 CNN</img>\n",
    "\n",
    "<img src=\"images/fig 8-2.png\">인식하지 못한(misclassified) 이미지들</img>\n",
    "\n",
    "### 8.1.2 정확도를 더 높이려면 \n",
    "\n",
    "<img src=\"images/fig 8-3.png\">MNIST rankings</img>\n",
    "\n",
    "<img src=\"images/fig 8-4.png\">Data augmentation</img>\n",
    "\n",
    "### 8.1.3 깊게 하는 이유 \n",
    "\n",
    "<img src=\"images/fig 8-5.png\">5x5 convolution</img>\n",
    "\n",
    "<img src=\"images/fig 8-6.png\">Multiple 3x3 convoltions</img>\n",
    "\n",
    "## 8.2 딥러닝의 초기 역사 \n",
    "### 8.2.1 이미지넷 \n",
    "<img src=\"images/fig 8-7.png\">ImageNet samples</img>\n",
    "\n",
    "<img src=\"images/fig 8-8.png\">ILSVRC rankings</img>\n",
    "\n",
    "### 8.2.2 VGG \n",
    "<img src=\"images/fig 8-9.png\">VGGNet</img>\n",
    "\n",
    "### 8.2.3 GoogLeNet \n",
    "<img src=\"images/fig 8-10.png\">GoogLeNet</img>\n",
    "\n",
    "<img src=\"images/fig 8-11.png\">Inception module in GoogLeNet</img>\n",
    "\n",
    "### 8.2.4 ResNet \n",
    "<img src=\"images/fig 8-12.png\">ResNet module</img>\n",
    "\n",
    "<img src=\"images/fig 8-13.png\">RegNet</img>\n",
    "\n",
    "## 8.3 더 빠르게(딥러닝 고속화) \n",
    "### 8.3.1 풀어야 할 숙제 \n",
    "<img src=\"images/fig 8-14.png\">AlextNet forward 처리시 각 층의 시간비율</img>\n",
    "\n",
    "### 8.3.2 GPU를 활용한 고속화 \n",
    "<img src=\"images/fig 8-15.png\">AlexNet 시간비교</img>\n",
    "\n",
    "### 8.3.3 분산 학습 \n",
    "<img src=\"images/fig 8-16.png\">완전연결 계층(Affine 계층)으로 이루어진 네트워크의 예</img>\n",
    "\n",
    "### 8.3.4 연산 정밀도와 비트 줄이기 \n",
    "\n",
    "## 8.4 딥러닝의 활용 \n",
    "### 8.4.1 사물 검출 \n",
    "<img src=\"images/fig 8-17.png\">사물 검출의 예시</img>\n",
    "\n",
    "<img src=\"images/fig 8-18.png\">R-CNN</img>\n",
    "\n",
    "### 8.4.2 분할 \n",
    "<img src=\"images/fig 8-19.png\">Segmentation</img>\n",
    "\n",
    "<img src=\"images/fig 8-20.png\">FCN</img>\n",
    "\n",
    "### 8.4.3 사진 캡션 생성 \n",
    "<img src=\"images/fig 8-21.png\">Image Captioning</img>\n",
    "\n",
    "<img src=\"images/fig 8-22.png\">NIC</img>\n",
    "\n",
    "## 8.5 딥러닝의 미래 \n",
    "### 8.5.1 이미지 스타일(화풍) 변환 \n",
    "<img src=\"images/fig 8-23.png\">A Neural Algorithm of Artistic Style</img>\n",
    "\n",
    "### 8.5.2 이미지 생성 \n",
    "<img src=\"images/fig 8-24.png\">DCGAN</img>\n",
    "\n",
    "### 8.5.3 자율 주행 \n",
    "<img src=\"images/fig 8-25.png\">딥러닝을 활용한 이미지 분할의 예</img>\n",
    "\n",
    "### 8.5.4 Deep Q-Network(강화학습) \n",
    "<img src=\"images/fig 8-26.png\">강화학습의 기본 틀</img>\n",
    "\n",
    "<img src=\"images/fig 8-27.png\">Deep Q-Network</img>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
